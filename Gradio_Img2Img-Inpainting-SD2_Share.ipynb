{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee75a38b",
   "metadata": {},
   "source": [
    "## SD2 Img-to-Img and Inpainting - Gradio for Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc3479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/ubuntu/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82d74d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1670231630732,
     "user": {
      "displayName": "Seulkee Lee",
      "userId": "14463507896336644914"
     },
     "user_tz": 480
    },
    "id": "L52bmJXkAMQz",
    "outputId": "f15b7cf8-9a89-40f3-fb78-ef293eb6eafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A10G, 23028 MiB, 22592 MiB\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fce102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10326,
     "status": "ok",
     "timestamp": 1670231645288,
     "user": {
      "displayName": "Seulkee Lee",
      "userId": "14463507896336644914"
     },
     "user_tz": 480
    },
    "id": "n9AmMcAGASDq",
    "outputId": "2700f34a-522a-472f-c81e-cc40f7f60cb9"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade diffusers==0.10.0 transformers ftfy scipy\n",
    "!pip install -qq \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad967e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: triton in /opt/conda/envs/pytorch/lib/python3.9/site-packages (0.4.2)\n",
      "Collecting triton\n",
      "  Using cached triton-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from triton) (1.13.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from triton) (3.6.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from torch->triton) (4.4.0)\n",
      "Installing collected packages: triton\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 0.4.2\n",
      "    Uninstalling triton-0.4.2:\n",
      "      Successfully uninstalled triton-0.4.2\n",
      "Successfully installed triton-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d61a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070524d9",
   "metadata": {
    "id": "HjWs9PenwLls"
   },
   "outputs": [],
   "source": [
    "!pip install -q accelerate==0.12.0 bitsandbytes gradio natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71d2618",
   "metadata": {
    "id": "2YJrHBHlB54B"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import warnings\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import autocast\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers import StableDiffusionInpaintPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5f7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler, DDPMScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "430ac2ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "79bffd0ad0f54a4fa535b056c3fe8b09",
      "df4c5b1dbbb54ddfb23b44ba0181e9b6",
      "af4f635ab5234f24a14ff52a4bb75baf",
      "57160ddcfdf14c3681e7eb8e5d249720",
      "014bfd890c7e4b409903ef8a2af91354",
      "ed6d18cd4c3a42378522f52e9e2f7019",
      "07b62980ce924d05a65297e07e4c5608",
      "57e980346ad447e3acc1fe97d43e651e",
      "208ba32104a74dbdaa22ebb4e435de62",
      "acdbee97dda74433a844366e541669d7",
      "a3b988ae9b9d42d3bbc0b91b6d337cd9"
     ]
    },
    "executionInfo": {
     "elapsed": 30316,
     "status": "ok",
     "timestamp": 1670231703398,
     "user": {
      "displayName": "Seulkee Lee",
      "userId": "14463507896336644914"
     },
     "user_tz": 480
    },
    "id": "Fr2QIEzvCFH2",
    "outputId": "aa75b978-0528-42a2-95f9-eeb0408e2ef6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489e29d9caa84ca69819217ecb0b905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_i2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2\",\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4cd209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1ed89e732f4532b5e17b27d9e8bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f1cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_i2i(option):\n",
    "    if option =='PNDM':\n",
    "        pipe_i2i.scheduler=PNDMScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'DDIM':\n",
    "        pipe_i2i.scheduler=DDIMScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'LMSDiscrete':\n",
    "        pipe_i2i.scheduler=LMSDiscreteScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'DDPM':\n",
    "        pipe_i2i.scheduler=DDPMScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'EulerDiscrete':\n",
    "        pipe_i2i.scheduler=EulerDiscreteScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'EulerAncestral':\n",
    "        pipe_i2i.scheduler=EulerAncestralDiscreteScheduler.from_config(pipe_i2i.scheduler.config)\n",
    "    elif option == 'DPMSolverMultistep':\n",
    "        pipe_i2i.scheduler=DPMSolverMultistepScheduler.from_config(pipe_i2i.scheduler.config)  \n",
    "    return pipe_i2i.scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ff4e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_inpaint(option):\n",
    "    if option =='PNDM':\n",
    "        pipe_inpaint.scheduler=PNDMScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'DDIM':\n",
    "        pipe_inpaint.scheduler=DDIMScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'LMSDiscrete':\n",
    "        pipe_inpaint.scheduler=LMSDiscreteScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'DDPM':\n",
    "        pipe_inpaint.scheduler=DDPMScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'EulerDiscrete':\n",
    "        pipe_inpaint.scheduler=EulerDiscreteScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'EulerAncestral':\n",
    "        pipe_inpaint.scheduler=EulerAncestralDiscreteScheduler.from_config(pipe_inpaint.scheduler.config)\n",
    "    elif option == 'DPMSolverMultistep':\n",
    "        pipe_inpaint.scheduler=DPMSolverMultistepScheduler.from_config(pipe_inpaint.scheduler.config)  \n",
    "    return pipe_inpaint.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e54c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_size(img):\n",
    "    \"\"\"Resize (scale down) input image size, if max length > 768. Width and height ratio kept same as original.\"\"\"\n",
    "    \n",
    "    bigger = max(img.size[0], img.size[1])\n",
    "    if bigger > 768:\n",
    "        ratio = 768 / bigger\n",
    "        new_width = int(img.size[0] * ratio)\n",
    "        new_height = int(img.size[1] * ratio)\n",
    "        img = img.resize((new_width, new_height))\n",
    "    else:\n",
    "        img = img\n",
    "    return img  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec556143",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4a77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_img(init_img, prompt, n_prompt, option, strength, guidance_scale, num_images, manual_seed):    \n",
    "    generator = torch.Generator('cuda')\n",
    "    scheduler_i2i(option)    \n",
    "    init_img=init_img.convert(\"RGB\")\n",
    "    init_img = re_size(init_img)\n",
    "    \n",
    "    if manual_seed != \"\":\n",
    "        manual_seed = int(manual_seed)\n",
    "        \n",
    "        with autocast(\"cuda\"):\n",
    "            image = pipe_i2i(image=init_img, \n",
    "                         prompt=prompt, \n",
    "                         negative_prompt=n_prompt, \n",
    "                         strength=strength, \n",
    "                         guidance_scale=guidance_scale, \n",
    "                         generator=generator.manual_seed(manual_seed)\n",
    "                        ).images[0]\n",
    "            images = [image, image]\n",
    "            seeds = manual_seed\n",
    "         \n",
    "    if manual_seed == \"\":\n",
    "        seeds = []\n",
    "        for i in range(num_images):\n",
    "            seed = generator.seed()\n",
    "            seeds.append(seed)\n",
    "        \n",
    "        images=[]\n",
    "        with autocast(\"cuda\"):\n",
    "            for seed in seeds:\n",
    "                image = pipe_i2i(image=init_img, \n",
    "                             prompt=prompt, \n",
    "                             negative_prompt=n_prompt, \n",
    "                             strength=strength, \n",
    "                             guidance_scale=guidance_scale, \n",
    "                             generator=generator.manual_seed(seed)\n",
    "                            ).images[0]\n",
    "                images.append(image)\n",
    "                \n",
    "    return images, str(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7213c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint(dict, prompt, n_prompt, option, inference_steps, guidance_scale, num_images):  \n",
    "    scheduler_inpaint(option)\n",
    "    image =  dict['image'].convert(\"RGB\")\n",
    "    image = re_size(image)\n",
    "    mask_image = dict['mask'].convert(\"RGB\")\n",
    "    mask_image = re_size(mask_image)\n",
    "    \n",
    "    seeds = []\n",
    "    for i in range(num_images):\n",
    "        seed = generator.seed()\n",
    "        seeds.append(seed)\n",
    "\n",
    "    images=[]\n",
    "    with autocast(\"cuda\"):\n",
    "        for seed in seeds:   \n",
    "            output = pipe_inpaint(prompt=prompt, \n",
    "                          negative_prompt=n_prompt, \n",
    "                          image=image, \n",
    "                          mask_image=mask_image, \n",
    "                          width = image.size[0],\n",
    "                          height = image.size[1],\n",
    "                          num_inference_steps=inference_steps,\n",
    "                          guidance_scale=guidance_scale,\n",
    "                          generator=generator.manual_seed(seed)  \n",
    "                          ).images[0]\n",
    "            images.append(output)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818c80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://a2d9c6d89f0c4bc8.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a2d9c6d89f0c4bc8.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/gradio/routes.py\", line 297, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/gradio/blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/gradio/blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_3818/4069909521.py\", line 16, in inpaint\n",
      "    output = pipe_inpaint(prompt=prompt,\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py\", line 583, in __call__\n",
      "    self.check_inputs(prompt, height, width, callback_steps)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py\", line 438, in check_inputs\n",
      "    raise ValueError(f\"`height` and `width` have to be divisible by 8 but are {height} and {width}.\")\n",
      "ValueError: `height` and `width` have to be divisible by 8 but are 733 and 768.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbda31bc99048fa84845ee2649243ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(label=\"Image-to-Image\"):\n",
    "        with gr.Row():\n",
    "            markdown = gr.Markdown(\"Upload an initial sketch or image to be used as a reference.\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                init_img = gr.Image(source = 'upload', type = 'pil')\n",
    "                prompt = gr.Textbox(label = 'Prompt', placeholder=\"Describe the image you would like to generate\")\n",
    "                n_prompt = gr.Textbox(label = 'Negative Prompt', placeholder=\"Unwanted in the generated image\")\n",
    "                strength = gr.Slider(minimum=0, maximum=1, value=0.75, step=0.05, label='Variation from Initial Image', interactive=True)\n",
    "                guidance_scale = gr.Slider(minimum=0, maximum=20, value=8.5, step=0.5, label='Prompt Guidance Scale (Typically 7.5 - 12.5)', interactive=True)\n",
    "                num_images = gr.Slider(minimum=1, maximum=4, value=2, step=1, label='Number of Images per Run', interactive=True)\n",
    "                manual_seed = gr.Textbox(label = 'Choose One Seed Number, Otherwise Automatically Generated')\n",
    "            with gr.Column(scale=1):\n",
    "                output1 = gr.Gallery()\n",
    "                with gr.Row():\n",
    "                    btn1 = gr.Button(value=\"Generate Image\")\n",
    "                    btn2 = gr.Button(value=\"TBD\")\n",
    "                output2 = gr.Textbox(label = 'Seeds Used')\n",
    "        with gr.Row():      \n",
    "            option = gr.Radio(choices=['DDIM', 'PNDM', 'LMSDiscret', 'DDPM', 'EulerDiscrete', 'EulerAncestral', \n",
    "                                       'DPMSolverMultistep'], value='DDIM', label='Choose Inference Schedule Method', interactive=True)\n",
    "        option.change(fn=scheduler_i2i, inputs=option)\n",
    "        btn1.click(fn=img_img, inputs=[init_img, prompt, n_prompt, option, strength, guidance_scale, num_images, manual_seed], \n",
    "                   outputs=[output1, output2])\n",
    "            \n",
    "    with gr.Tab(label=\"Inpaint\"):\n",
    "        with gr.Row():\n",
    "            markdown = gr.Markdown(\"Upload an image and draw mask where you want a change.\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                dict=gr.Image(source = 'upload', tool = 'sketch', type = 'pil')\n",
    "                prompt = gr.Textbox(label = 'Prompt', placeholder=\"Describe what you want to replace the mask with\")\n",
    "                n_prompt = gr.Textbox(label = 'Negative Prompt', placeholder=\"Unwanted in the generated image\") \n",
    "                num_images = gr.Slider(minimum=1, maximum=4, value=2, step=1, label='Number of Samples per Run', interactive=True)\n",
    "                guidance_scale = gr.Slider(minimum=0, maximum=20, value=8.5, step=0.5, \n",
    "                                            label='Guidance Scale (Typically between 7.5 and 12.5)', interactive=True)                     \n",
    "                inference_steps = gr.Slider(minimum=10, maximum=400, value=100, step=10, \n",
    "                                            label='Number of Steps for Inference', interactive=True)                        \n",
    "            with gr.Column(scale=1):\n",
    "                output = gr.Gallery()\n",
    "                with gr.Row():\n",
    "                    btn1 = gr.Button(value=\"Modify Image\")\n",
    "                    btn2 = gr.Button(value=\"TBD\")\n",
    "        with gr.Row():      \n",
    "            option = gr.Radio(choices=['DDIM', 'PNDM', 'LMSDiscret', 'DDPM', 'EulerDiscrete', 'EulerAncestral', \n",
    "                                       'DPMSolverMultistep'], value='PNDM', label='Choose Inference Schedule Method', interactive=True)\n",
    "        option.change(fn=scheduler_inpaint, inputs=option)\n",
    "        btn1.click(fn=inpaint, inputs=[dict, prompt, n_prompt, option, inference_steps, guidance_scale, num_images], outputs=output)\n",
    "        \n",
    "demo.launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
